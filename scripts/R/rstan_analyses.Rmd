---
title: "bayesParcel R/Stan analyses"
author: "The Best Group Ever (Paul, Yaniv, Monica)"
date: "11/28/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(tidyverse)
theme_set(theme_bw())
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(data.table)
library(moments)
```
# Introduction
Paul

## Loading real data

```{r}
betas_raw <- read_csv("../../ignore/harvard_ox_roi.csv")

betas <- betas_raw %>%
  gather(key = "roi", value = "value", -Subject, -wave, -meanFD_included_trs) %>%
  filter(!is.na(value)) %>%
  mutate(statistic = if_else(grepl("Mean", roi), "cope_mean", "cope_sd"),
         roi = if_else(statistic == "cope_mean",
                       stringr::str_sub(roi, end = -5L),
                       stringr::str_sub(roi, end = -3L))) %>%
  spread(statistic, value) %>%
  # BAND AID!!! but we need ot filter cope_sd > 0. some shit failed
  filter(cope_sd > 0, wave == 1) %>%
  group_by(Subject) %>%
  nest() %>%
  mutate(subject_num = 1:n()) %>%
  unnest() %>%
  group_by(roi) %>%
  nest() %>%
  mutate(roi_num = 1:n()) %>%
  unnest() %>%
  mutate(cope_mean_scaled = cope_mean / sd(cope_mean),
         cope_sd_scaled = cope_sd / sd(cope_mean))

```

```{r}
# Exclude nonsense ROIs
exclude <- c('harvardox_subcortical_1', 'harvardox_subcortical_2', 'harvardox_subcortical_8',
             'harvardox_subcortical_12', 'harvardox_subcortical_13')
betas <- subset(betas, !(roi %in% exclude))
```

# Model 0: Single normal hyper-distribution
As a starting point, we chose to model COPE responses in the different ROIs with a model based on the 8-school example. As such, this is a hierarchical model, with each ROI drawn from a population of ROIs with a normal distribution, and each subject drawn from a population of subjects with a normal distribution. Thus, the likelihood in our model is:
$$COPE_{i} \sim normal(\alpha + \tau_{ROI} * \eta_{ROI[i]} + \tau_{subject} * \eta_{subject[i]}) $$
With $\alpha$ being a general intercept term, $\eta$s as the ROI- and subject-wise deviations from the general intercept, and $\tau$s as the variation factor for the deviations.
Following the 8-school model, we chose normal mid-level priors for ROIs and subjects:
$$\eta_{subject} \sim normal(0,1)$$
$$\eta_{ROI} \sim normal(0,1)$$
Finally, we used non-informative priors for the variance and general expected value hyper parameters ($\alpha$ and $\tau_{subject / ROI}$), for regularization purposes.

## Stan code
```{stan, output.var = "model0", results = "hide", message = FALSE, warning = FALSE}
data {
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  real cope[N];               // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> fd[N]; // framewise displacement of each observation, varies by subject x wave
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
transformed data {
  int<lower=0> N_cell = N_roi * N_subj;
}
parameters {
  real alpha; // intercept 
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  vector[N_roi] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
model {
  // priors make the world go round
  alpha ~ normal(0, 1);
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  eta_roi ~ normal(0, 1);
  eta_subj ~ normal(0, 1);
  // completely pooled across observations here
  cope ~ normal(alpha + tau_roi * eta_roi[roi] + tau_subj * eta_subj[subj], varcope);
}
generated quantities {
  vector[N_roi] theta_roi = alpha + tau_roi * eta_roi;
  vector[N_subj] theta_subj = alpha + tau_subj * eta_subj;
  
  vector [N] rep_cope; // Create data replicates

  for (i in 1:N)
    rep_cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}
```
## Fake data simulation
Before fitting the model to the data, we'll begin by evaluating the model's potency in recovering known parameters. We used Stan to simulate data given parameters drawn from the priors in our model. We then fit the simulated data, and checked the resultant posterior intervals against the know values of the parameters. 
```{stan, output.var = "model0_fake", results = "hide", message = FALSE, warning = FALSE}
data {
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
parameters {
  real alpha; // intercept 
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  vector[N_roi] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
model {
  // priors make the world go round
  alpha ~ normal(0, 1);
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  eta_roi ~ normal(0, 1);
  eta_subj ~ normal(0, 1);
}
generated quantities {
  vector [N] cope; // Create data replicates
  for (i in 1:N)
    cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}
```

```{r results = "hide", message = FALSE, warning = FALSE}
# Draw fake data
fake_data0 <- sampling(model0_fake, data = betas %$%
                   list(N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                   iter = 1, warmup = 0, chain = 1, seed = 78)

# Fake data book keeping
fake_data0 <- as.data.table(fake_data0)
fake_params0 <- fake_data0[, !grepl('cope', colnames(fake_data0)), with = F]
fake_data0 <- fake_data0[, grepl('cope', colnames(fake_data0)), with = F]
fake_data0 <- melt(fake_data0, measure.vars = colnames(fake_data0))
```

``` {r eval = F}
# Fit fake data
fake_fit0 <- sampling(model0,
                 data = betas %$%
                   list(N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = fake_data0$value,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 seed = 2323)
save(fake_fit0, file = "../../ignore/fake_fit0.rda")
```

```{r echo = F}
load("../../ignore/fake_fit0.rda")
```

```{r}
# Check parameter recovery
fake_fit0 <- as.data.table(fake_fit0)
fake_fit0 <- melt(fake_fit0, measure.vars = colnames(fake_fit0)) 
fake_fit0 <- fake_fit0[, .(median = median(value),
                           ub = quantile(value, 0.975),
                           lb = quantile(value, 0.025)), by = variable]
fake_params0 <- melt(fake_params0, measure.vars = colnames(fake_params0), value.name = 'trueVal')
fake_fit0 <- merge(fake_fit0, fake_params0, by = 'variable')
fake_fit0 <- fake_fit0[!grepl('lp_', variable, fixed = T),]

ggplot(fake_fit0[grepl('eta_roi',variable),], aes(x = median, y = variable)) +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) +
  geom_point() +
  geom_point(aes(x = trueVal), color = 'red') +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(x = 'Parameter value',
       title = 'Simulated data parameter recover: eta_ROI',
       subtitle = 'Black: posterior median and 95% interval. Red: true parameter value')

ggplot(fake_fit0[grepl('eta_subj',variable),], aes(x = median, y = variable)) +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) +
  geom_point() +
  geom_point(aes(x = trueVal), color = 'red') +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(x = 'Parameter value',
       title = 'Simulated data parameter recover: eta_subject',
       subtitle = 'Black: posterior median and 95% interval. Red: true parameter value')

ggplot(fake_fit0[!grepl('eta_roi',variable) &!grepl('eta_subj',variable),], 
       aes(x = median, y = variable)) +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) +
  geom_point() +
  geom_point(aes(x = trueVal), color = 'red') +
  labs(x = 'Parameter value',
       title = 'Simulated data parameter recover: hyperparameters',
       subtitle = 'Black: posterior median and 95% interval. Red: true parameter value')
```
As can be seen in the plots above, for the vast majority of parameters in this fit, the true value lies within the 95% posterior interval, as we would expect. Since we drew parameters from the priors for our model, we can see this result as rather general.

## Model fit to data
Next, we fit the observed data with our model.
```{r, eval = FALSE}
fit0 <- sampling(model0,
                 data = betas %$%
                   list(N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = cope_mean_scaled,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 control = list(max_treedepth = 15),
                 seed = 909)

save(fit0, file = "../../ignore/fit_model0.rda")
```

```{r echo = F}
load("../../ignore/fit_model0.rda")
```

```{r}
df_fit0 <- fit0 %>%
  as.data.frame() %>%
  as_tibble() %>%
  mutate(iteration = 1:n())

hyperparams <- df_fit0 %>%
  select(iteration, alpha, tau_roi, tau_subj)

theta_rois <- df_fit0 %>%
  select(iteration, starts_with("theta_roi")) %>%
  gather(key = "roi_num", value = "theta", starts_with("theta_roi")) %>%
  mutate(roi_num = as.integer(str_sub(roi_num, start = 11L, end = -2L)),
         theta_unscaled = theta * sd(betas$cope_mean)) %>%
  group_by(roi_num) %>%
  nest(.key = "iterations") %>%
  left_join(betas %>%
              select(roi_num, cope_mean, cope_mean_scaled) %>%
              group_by(roi_num) %>%
              summarize_all(mean),
            by = "roi_num") %>%
  mutate(summaries = map(iterations, ~.x %>%
                           summarize_at(vars(starts_with("theta")),
                                        funs(median = median,
                                             int_95_lower = quantile(., .025),
                                             int_95_upper = quantile(., .975),
                                             int_50_lower = quantile(., .25),
                                             int_50_upper = quantile(., .75))))) %>%
  unnest(summaries, .preserve = "iterations")


```

After fitting the model, we proceeded to perform some model check and evaluations. Comparing the observed COPE values to the estimated posterior intervals, we find that the estimated intervals are pooled towards the sample mean, in comparison to the raw values. The plot below illustrates this point. This is an expected advantageous feature of the hierarchical model, which allows partial pooling of estimates across ROIs and subjects.
```{r}
theta_rois %>%
  ggplot(aes(x = roi_num)) +
  geom_hline(yintercept = 0, linetype = 3) +
  geom_errorbar(aes(ymin = theta_int_95_lower, ymax = theta_int_95_upper), width = 0) +
  geom_point(aes(y = theta_median)) +
  geom_point(aes(y = cope_mean_scaled), color = "hotpink") +
  labs(x = "ROI number (arbitrary)",
       y = "COPE/beta value (SCALED arbitrary units)",
       title = "Bayesian estimates against original marginal means",
       subtitle = "Black: median estimates +- 95% predictive interval, pink: original mean estimate") +
  theme_bw()
```

### Brain plots

### Posterior predictive checks
To further evaluate the adequacy of the hierarchical normal model to the data, we performed posterior predictive checks. For each posterior draw, simulated data were generated with the same model likelihood, given the drawn parameters. These posterior replicates allow us to plot the interval of expected new observations, given our model and the observed data. Comparing our observed data to the predictive interval informs us about the adequacy of the chosen model.
As can be seen of in the plots of replicates and observed data below, the observed data all fall withing the 95% interval of replicates. Thus, the data are plausible given the generative model. A drawback highlighted by this test, is that the median replicates are do not follow the observed data well at the extreme tails of the distribution: that is, the observed data seems to have consistently heavier tails than than the replicate data.
```{r}
# Plot data replicates
# Implemented with data.table. Sorry. Open to the possibility of recoding with tidyverse, just not right now
df_fit0 <- as.data.table(fit0)
df_fit0 <- df_fit0[, grepl('rep_cope', colnames(df_fit0)), with = F]
df_fit0[, sim := 1:nrow(df_fit0)]
df_fit0 <- melt(df_fit0, id.vars = 'sim')
df_fit0[, value := value * sd(betas$cope_mean)]
df_fit0 <- df_fit0[, .(median = median(value),
                     lb = quantile(value, 0.025),
                     ub = quantile(value, 0.975)), by = variable][order(variable)]
df_fit0[, subject_num := betas$subject_num]
df_fit0[, roi_num := betas$roi_num]
df_fit0[, true_value := betas$cope_mean]
df_fit0 <- df_fit0[order(true_value)]

# Plot disregarding heirarchy
ggplot(df_fit0, aes(x = 1:nrow(df_fit0), y = median)) +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = 'yellow') +
  geom_line(color = 'darkred') + 
  geom_point(aes(y = true_value)) +
  labs(x = 'Observation number',
       y = 'COPE',
       title = 'Posterior predictive checks: replicate plots ignoring heirarchy',
       subtitle = 'Red: posterior median. Yellow: posterior 95% interval. Black: observed COPE')

# Plot by subject
df_subs <- df_fit0[subject_num %in% sample(1:length(unique(subject_num)), 20)]
df_subs[, xplot := 1:.N, by = subject_num]
ggplot(df_subs, aes(x = xplot, y = median)) +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = 'yellow') +
  geom_point(aes(y = true_value), size = 0.3) +
  geom_line(color = 'darkred') + 
  facet_wrap('subject_num') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) +
  labs(x = 'Subject number (arbitrary)',
       y = 'COPE',
       title = 'Posterior predictive checks: replicate plots by subject, for a random subsample of subjects',
       subtitle = 'Red: posterior median. Yellow: posterior 95% interval. Black: observed COPE')

# Plot by roi
df_subs <- df_fit0[roi_num %in% sample(1:length(unique(roi_num)), 20)]
df_subs[, xplot := 1:.N, by = roi_num]
ggplot(df_subs, aes(x = xplot, y = median)) +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = 'yellow') +
  geom_point(aes(y = true_value), size = 0.3) +
  geom_line(color = 'darkred') + 
  facet_wrap('roi_num') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) +
  labs(x = 'ROI number (arbitrary)',
       y = 'COPE',
       title = 'Posterior predictive checks: replicate plots by ROI, for a random subsample of ROIs',
       subtitle = 'Red: posterior median. Yellow: posterior 95% interval. Black: observed COPE')

```
The heavier tails in the observed data indicated that our mid-level priors might not be the best fit for the data. Hence, we compared the estimated draws for the ROI and subject deviations from the mean COPE to the normal prior we assigned them. The plots below reveal that overall, the estimated deviations conform to the shape of the normal prior. However, when inspecting the plots for the ROIs, they seem to have a rightward skew and a heavier right tail that is not consistent with a normal prior.
```{r}
# Compare thetas to priors
df_fit0 <- as.data.table(fit0)
vars <- colnames(df_fit0)
eta_rois <- df_fit0[sample(1:nrow(df_fit0), 20), grepl('eta_roi', vars) & !grepl('th', vars), with = F]
eta_subj <- df_fit0[sample(1:nrow(df_fit0), 20), grepl('eta_subj', vars) & !grepl('th', vars), with = F]

eta_rois[, sim := 1:.N]
eta_subj[, sim := 1:.N]

eta_rois <- melt(eta_rois, id.vars = 'sim')
eta_subj <- melt(eta_subj, id.vars = 'sim')

bw <- .2
n_subj <- length(unique(eta_subj$variable))
ggplot(eta_subj, aes(x = value)) + 
  geom_histogram(binwidth = bw) +
  facet_wrap('sim') +
  stat_function(fun = function(x, bw, n) dnorm(x) * bw * n, 
                args = c(bw = bw, n = n_subj),
                color = 'blue') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) + 
  labs(x = expression(eta),
       title = 'Estimated subject deviations agains the normal prior distribution',
       subtitle = 'Black: subject histogram, Blue: normal prior, Each facet represents a posterior draw')

n_roi <- length(unique(eta_rois$variable))
ggplot(eta_rois, aes(x = value)) + 
  geom_histogram(binwidth = bw) +
  facet_wrap('sim') +
  stat_function(fun = function(x, bw, n) dnorm(x) * bw * n, 
                args = c(bw = bw, n = n_roi),
                color = 'blue') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) + 
  labs(x = expression(eta),
       title = 'Estimated ROI deviations agains the normal prior distribution',
       subtitle = 'Black: ROI histogram, Blue: normal prior, Each facet represents a posterior draw')

```
### Model 0 summary
Fitting a hierarchical normal model to the data, with normally distributed deviations for ROIs and subjects, seems like a good first choice for the data. The estimates are stable and interpretable, with observed data plausible given the generative model. However, a  tendency towards rightward skew in the distribution of estimated ROIs, and the comparison of replicates and observed data, prompted us to suspect that the extreme observations could be better modeled. This is in line with the modal theoretical view of imaging experiments: It is expected that regions in the brain should come from separate distributions. Commonly, it is assumed that a group of regions is positively activated by a given task, another group does not show activation, and possibly a third group shows negative values for the contrast of interest.

# Model 1: Finite mixture hyper-distribution

We decided that we would implement this theoretically motivated second model as a finite mixture model. In this case, we would assume one mixture component for "non-activated" regions, one mixture component for "negative-activated" regions, and one for "positive-activated" regions. In this way, we would be able to classify regions as activated vs. not based on their estimated probabilities of belonging to each mixture component.

For our first pass of the model, we tried our best to implement it without tailoring too many of the model elements (standard deviations on normal priors, for example) to observed features of the data. This is a little different than the usual strategy of visually exploring data to determine how best to fit a model to said data. We opted to do this to model how this analysis method might be used "in the wild." With most neuroimaging data, data are collected to fit a prescribed data structure (MRI image timeseries should be a certain structure, event markers for different sections of the timeseries should be labeled a certain way, etc), and researchers use a fairly stereotyped analysis pipeline that is robust to individual dataset-level variations. If we were to generalize the model we present here to future analyses, it would need to be completely generative, and thus not have parameters specified based on the data fed into it. If the generative model fits less well to the current dataset, we prefer that if the model can be generalized to future datasets without modification.

We opted to fit a mixture model with three ordered normal components. We constrained the first component to have a negative mean, the second component to have a mean of 0, and the third component to have a positive mean. We set the standard deviations of each of the mixture components to be equal, as we did not have a strong prior reason to believe the mixture components to have different spreads, and thus we wanted to minimize the number of parameters to be estimated.

We specified the $\eta_{ROI}$ and $\eta_{subject}$ parameters similarly to the first, single normal model, but this time we specified $\eta_{ROI}$ as a matrix with $N$ rows, one for each ROI (as before), and with $K$ columns, one for each mixture component (new). Each ROI has one $\eta_{ROI_k}$ value, conditional on the ROI being drawn from mixture component $k$.

We added two new sets of parameters, $\beta$, for the means of each of the mixture components, and $\phi$, for the latent variable indexing the probability that an observation would be drawn from a given mixture component.

### Delete me simulation maybe

```{r}
tibble(id = 1:2000) %>%
  mutate(mu_mixture = sample(-1:1, size = n(), replace = TRUE, prob = c(.25, .5, .25)),
         mu_single = 0,
         sigma = 0.5) %>%
  gather(key = "type", value = "mu", starts_with("mu")) %>%
  mutate(x = rnorm(n(), mean = mu, sd = sigma)) %>%
  ggplot(aes(x = x, fill = type)) +
  geom_histogram(position = "identity", alpha = 0.2)
```


### Stan code

```{stan, output.var = "model1", results = "hide", message = FALSE, warning = FALSE}
data {
  real beta_0;                          // middle mixture center
  int<lower=0> N;                       // number of ROIs x observations (subjs x waves)
  int<lower=0> N_roi;                   // number of ROIs
  int<lower=0> N_subj;                  // number of subjects
  real cope[N];                         // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N];     // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N];   // subject ID of each observation
  real<lower=0> varcope[N];             // s.e. of effect estimates
}
parameters {
  simplex[3] phi;           // mixing proportions
  real<upper=0> beta_neg;   // center of negative mixture component
  real<lower=0> beta_pos;   // center of positive mixture component
  real<lower=0> tau_roi;    // SD of hyper-distribution of eta_roi
  real<lower=0> tau_subj;   // SD of hyper-distribution of eta_subj
  matrix[N_roi, 3] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj;  // centered parameterization of roi-specific effect estimate
}
transformed parameters {
  /* hard coding 3 mixture components
  kind of hacky, but this was the easiest way we figured out */
  vector[3] beta;
  beta[1] = beta_neg;
  beta[2] = beta_0;
  beta[3] = beta_pos;
}
model {
  vector[3] log_phi = log(phi);  // cache log calculation
  
  // weakly informative prior for the two estimated betas
  beta_neg ~ normal(0, 5);
  beta_pos ~ normal(0, 5);
  
  // wip for taus
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  
  // wip for etas
  for (k in 1:3) {
    eta_roi[, k] ~ normal(0, 1);
  }
  
  eta_subj ~ normal(0, 1);
  
  // likelihood stuff
  for (n in 1:N) {
    vector[3] lps = log_phi;
    for (k in 1:3)
      lps[k] += normal_lpdf(cope[n] | beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]);
    target += log_sum_exp(lps);
  }
}
generated quantities {
  // generated thetas, one for each mixture component
  matrix[N_roi, 3] theta_roi;
  for (k in 1:3) {
    theta_roi[, k] = beta[k] + tau_roi * eta_roi[, k];
  }
}

```

```{r, eval = FALSE}
fit1.2 <- sampling(model1.2,
                 data = betas %$%
                   list(K = 2L,
                        N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = cope_mean_scaled,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 iter = 200,
                 control = list(max_treedepth = 15))
```

```{r, eval = FALSE}
fit1.3 <- sampling(model1.3,
                 data = betas %$%
                   list(K = 2L,
                        beta = c(0.3, 1),
                        N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = cope_mean_scaled,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 iter = 200,
                 control = list(max_treedepth = 15))
```

Inspecting the estimates for $\phi$ and $\beta$ reveals that the mixture model does not actually add any new information. $\phi_3$, the probability for the third (positive) mixture component, is functionally 1, while $\phi_1$ and $\phi_2$ are functionally 0. $\beta_3$ is estimated at about the mean of the observed data, while the other two mixture centers are estimated at 0--$\beta_2$ because we fixed it at 0, and $\beta_1$ presumably because it's centered at the mean value of the prior, and there are no data points that would pull the posterior estimate below 0.


```{stan, output.var = "model1.2", results = "hide", message = F, warning = F, eval = F}
data {
  int<lower=1> K;                       // number of mixture components
  int<lower=0> N;                       // number of ROIs x observations (subjs x waves)
  int<lower=0> N_roi;                   // number of ROIs
  int<lower=0> N_subj;                  // number of subjects
  real cope[N];                         // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N];     // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N];   // subject ID of each observation
  real<lower=0> varcope[N];             // s.e. of effect estimates
}
transformed data {
  int<lower=0> N_cell = N_roi * N_subj;
}
parameters {
  simplex[K] phi;           // mixing proportions
  ordered[K] beta;          // centers of mixture components
  real<lower=0> tau_roi;    // SD of hyper-distribution of eta_roi
  real<lower=0> tau_subj;   // SD of hyper-distribution of eta_subj
  matrix[N_roi, K] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj;  // centered parameterization of roi-specific effect estimate
}
model {
  vector[2] log_phi = log(phi);  // cache log calculation
  
  // weakly informative prior for all betas
  beta ~ normal(0, 2);
  
  // weakly informative prior for taus
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  
  // weakly informative prior for etas
  for (k in 1:K) {
    eta_roi[, k] ~ normal(0, 1);
  }
  
  eta_subj ~ normal(0, 1);
  
  // likelihood stuff
  for (n in 1:N) {
    vector[K] lps = log_phi;
    for (k in 1:K)
      lps[k] += normal_lpdf(cope[n] | beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]);
    target += log_sum_exp(lps);
  }
}

```

```{stan, output.var = "model1.3", results = "hide", message = F, warning = F eval = F}
data {
  int<lower=1> K;                       // number of mixture components
  ordered[K] beta;                      // centers of mixture components
  int<lower=0> N;                       // number of ROIs x observations (subjs x waves)
  int<lower=0> N_roi;                   // number of ROIs
  int<lower=0> N_subj;                  // number of subjects
  real cope[N];                         // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N];     // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N];   // subject ID of each observation
  real<lower=0> varcope[N];             // s.e. of effect estimates
}
parameters {
  simplex[K] phi;           // mixing proportions
  real<lower=0> tau_roi;    // SD of hyper-distribution of eta_roi
  real<lower=0> tau_subj;   // SD of hyper-distribution of eta_subj
  matrix[N_roi, K] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj;  // centered parameterization of roi-specific effect estimate
}
model {
  vector[2] log_phi = log(phi);  // cache log calculation
  
  // rather informative prior for all betas
  beta ~ normal(0, 1);
  
  // weakly informative prior for taus
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  
  // weakly informative prior for etas
  for (k in 1:K) {
    eta_roi[, k] ~ normal(0, 1);
  }
  
  eta_subj ~ normal(0, 1);
  
  // likelihood stuff
  for (n in 1:N) {
    vector[K] lps = log_phi;
    for (k in 1:K)
      lps[k] += normal_lpdf(cope[n] | beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]);
    target += log_sum_exp(lps);
  }
}

```

## Attempts to refine model

We opted not to spend time running posterior predictive checks or other model evaluation on the first iteration of our mixture model, as we could tell immediately from checking the mixture parameter estimates that Stan had estimated our model as having essentially only one component.

We tried modifying the mixture model to remedy the non-mixture-estimation issue in the following ways. Stan code printed for transparency, but model outputs hidden for clarity, as we found that all of the modified models continued suffering from the problem of having one mixture component with $\phi \approx 1$ and the rest with $\phi \approx 0$.

First, we cut the number of mixture components down to two, as we observed in the original single normal hierarchical model that there were hardly any ROIs for which $\eta_{ROI}$ was "deactivated", or much below 0. This way, we should only be estimating the "non-activated" and the "positive-activated" mixture components. We also stopped hard-coding the number of components, or the location of any of the components, in this model.


### Plots?

Temporarily need to reload model object when done separately
```{r, echo = FALSE, eval = FALSE}
load('fit_model0.rda')

## Redundant bit
# 
# df_fit0 <- fit %>%
#   as.data.frame() %>%
#   as_tibble() %>%
#   mutate(iteration = 1:n())
# 
# theta_rois <- df_fit0 %>%
#   select(iteration, starts_with("theta_roi")) %>%
#   gather(key = "roi_num", value = "theta", starts_with("theta_roi")) %>%
#   mutate(roi_num = as.integer(stringr::str_sub(roi_num, start = 11L, end = -2L)),
#          theta_unscaled = theta * sd(betas$cope_mean)) %>%
#   group_by(roi_num) %>%
#   nest(.key = "iterations") %>%
#   left_join(betas %>%
#               select(roi_num, cope_mean, cope_mean_scaled) %>%
#               group_by(roi_num) %>%
#               summarize_all(mean),
#             by = "roi_num") %>%
#   mutate(summaries = map(iterations, ~.x %>%
#                            summarize_at(vars(starts_with("theta")),
#                                         funs(median = median,
#                                              int_95_lower = quantile(., .025),
#                                              int_95_upper = quantile(., .975),
#                                              int_50_lower = quantile(., .25),
#                                              int_50_upper = quantile(., .75))))) %>%
#   unnest(summaries, .preserve = "iterations") 

# Save out the thetas for each roi
theta_rois = dplyr::select(betas, roi, roi_num) %>%
  unique() %>%
  left_join(theta_rois, .) %>%
  select(-iterations)

write.csv(theta_rois, file = '../../estimates/spreadsheets/mod0.csv', row.names = F, quote = F)
```

# Discussion

## Why we trashed the mixture models
```{r}
betas %>%
  ggplot(aes(x = roi_num, y = cope_mean_scaled)) +
  geom_errorbar(aes(ymin = cope_mean_scaled - cope_sd_scaled, ymax = cope_mean_scaled + cope_sd_scaled), width = 0, alpha = 0.3) +
  geom_point(alpha = 0.3)

ggplot(betas, aes(x = cope_mean_scaled)) +
  geom_histogram(binwidth=.2)

summary(betas)
```

## Future directions for neuroscience in general
Paul