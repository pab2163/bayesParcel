---
title: "bayesParcel R/Stan analyses"
author: "The Best Group Ever (Paul, Yaniv, Monica)"
date: "11/28/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(tidyverse)
theme_set(theme_bw())
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(data.table)
library(moments)
```

## Loading real data

```{r}
betas_raw <- read_csv("../../ignore/harvard_ox_roi.csv")

betas <- betas_raw %>%
  gather(key = "roi", value = "value", -Subject, -wave, -meanFD_included_trs) %>%
  filter(!is.na(value)) %>%
  mutate(statistic = if_else(grepl("Mean", roi), "cope_mean", "cope_sd"),
         roi = if_else(statistic == "cope_mean",
                       stringr::str_sub(roi, end = -5L),
                       stringr::str_sub(roi, end = -3L))) %>%
  spread(statistic, value) %>%
  # BAND AID!!! but we need ot filter cope_sd > 0. some shit failed
  filter(cope_sd > 0, wave == 1) %>%
  group_by(Subject) %>%
  nest() %>%
  mutate(subject_num = 1:n()) %>%
  unnest() %>%
  group_by(roi) %>%
  nest() %>%
  mutate(roi_num = 1:n()) %>%
  unnest() %>%
  mutate(cope_mean_scaled = cope_mean / sd(cope_mean),
         cope_sd_scaled = cope_sd / sd(cope_mean))

<<<<<<< HEAD
```{r}
betas %>%
  ggplot(aes(x = roi_num, y = cope_mean_scaled)) +
  geom_errorbar(aes(ymin = cope_mean_scaled - cope_sd_scaled, ymax = cope_mean_scaled + cope_sd_scaled), width = 0, alpha = 0.3) +
  geom_point(alpha = 0.3)
```


## Simulating data
=======
# Exclude nonsense ROIs
exclude <- c('harvardox_subcortical_1', 'harvardox_subcortical_2', 'harvardox_subcortical_8',
             'harvardox_subcortical_12', 'harvardox_subcortical_13')
betas <- subset(betas, !(roi %in% exclude))
```
>>>>>>> c07978bc6a6cc986c2a2192f99ef6c9d21813eee

## Model 0: Single normal hyper-distribution
As a starting point, we chose to model COPE responses in the different ROIs with a model based on the 8-school example. As such, this is a heirarchical model, with each ROI drawn from a population of ROIs with a normal distribution, and each subject drawn from a population of subjects with a normal distribution. Thus, the likelihood in our model is:
$$COPE_{i} \sim normal(\alpha + \tau_{ROI} * \eta_{ROI[i]} + \tau_{subject} * \eta_{subject[i]}) $$
With mid-level priors for ROI and subject being:
$$\eta_{subject} \sim normal(0,1)$$
$$\eta_{ROI} \sim normal(0,1)$$
Finally, we used non-informative priors for the variance and general expected value hyper parameters ($\alpha$ and $\tau_{subject / ROI}$), for regulaization purposes.

### Stan code
```{stan, output.var = "model0", results = "hide", message = FALSE, warning = FALSE}
data {
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  real cope[N];               // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> fd[N]; // framewise displacement of each observation, varies by subject x wave
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
transformed data {
  int<lower=0> N_cell = N_roi * N_subj;
}
parameters {
  real alpha; // intercept 
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  vector[N_roi] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
model {
  // priors make the world go round
  alpha ~ normal(0, 1);
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  eta_roi ~ normal(0, 1);
  eta_subj ~ normal(0, 1);
  // completely pooled across observations here
  cope ~ normal(alpha + tau_roi * eta_roi[roi] + tau_subj * eta_subj[subj], varcope);
}
generated quantities {
  vector[N_roi] theta_roi = alpha + tau_roi * eta_roi;
  vector[N_subj] theta_subj = alpha + tau_subj * eta_subj;
  
  vector [N] rep_cope; // Create data replicates

  for (i in 1:N)
    rep_cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}
```
### Fake data simulation
Before fitting the model to the data, we'll begin by evaluating the model's potency in recovering known parameters. We used Stan to simulate data given parameters drawn from the priors in our model. We then fit the simulated data, and checked the resultant posterior intervals against the know values of the parameters. 
```{stan, output.var = "model0_fake", results = "hide", message = FALSE, warning = FALSE}
data {
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
parameters {
  real alpha; // intercept 
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  vector[N_roi] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
model {
  // priors make the world go round
  alpha ~ normal(0, 1);
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  eta_roi ~ normal(0, 1);
  eta_subj ~ normal(0, 1);
}
generated quantities {
  vector [N] cope; // Create data replicates
  for (i in 1:N)
    cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}
```

```{r results = "hide", message = FALSE, warning = FALSE}
# Draw fake data
fake_data0 <- sampling(model0_fake, data = betas %$%
                   list(N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                   iter = 1, warmup = 0, chain = 1, seed = 78)

# Fake data book keeping
fake_data0 <- as.data.table(fake_data0)
fake_params0 <- fake_data0[, !grepl('cope', colnames(fake_data0)), with = F]
fake_data0 <- fake_data0[, grepl('cope', colnames(fake_data0)), with = F]
fake_data0 <- melt(fake_data0, measure.vars = colnames(fake_data0))
```

``` {r eval = F}
# Fit fake data
fake_fit0 <- sampling(model0,
                 data = betas %$%
                   list(N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = fake_data0$value,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 seed = 2323)
save(fake_fit0, file = "../../ignore/fake_fit0.rda")
```

```{r echo = F}
load("../../ignore/fake_fit0.rda")
```

```{r}
# Check parameter recovery
fake_fit0 <- as.data.table(fake_fit0)
fake_fit0 <- melt(fake_fit0, measure.vars = colnames(fake_fit0)) 
fake_fit0 <- fake_fit0[, .(median = median(value),
                           ub = quantile(value, 0.975),
                           lb = quantile(value, 0.025)), by = variable]
fake_params0 <- melt(fake_params0, measure.vars = colnames(fake_params0), value.name = 'trueVal')
fake_fit0 <- merge(fake_fit0, fake_params0, by = 'variable')
fake_fit0 <- fake_fit0[!grepl('lp_', variable, fixed = T),]

ggplot(fake_fit0[grepl('eta_roi',variable),], aes(x = median, y = variable)) +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) +
  geom_point() +
  geom_point(aes(x = trueVal), color = 'red') +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(x = 'Parameter value',
       title = 'Simulated data parameter recover: eta_ROI',
       subtitle = 'Black: posterior median and 95% interval. Red: true parameter value')

ggplot(fake_fit0[grepl('eta_subj',variable),], aes(x = median, y = variable)) +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) +
  geom_point() +
  geom_point(aes(x = trueVal), color = 'red') +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(x = 'Parameter value',
       title = 'Simulated data parameter recover: eta_subject',
       subtitle = 'Black: posterior median and 95% interval. Red: true parameter value')

ggplot(fake_fit0[!grepl('eta_roi',variable) &!grepl('eta_subj',variable),], 
       aes(x = median, y = variable)) +
  geom_errorbarh(aes(xmin = lb, xmax = ub)) +
  geom_point() +
  geom_point(aes(x = trueVal), color = 'red') +
  labs(x = 'Parameter value',
       title = 'Simulated data parameter recover: hyperparameters',
       subtitle = 'Black: posterior median and 95% interval. Red: true parameter value')
```
As can be seen in the plots above, for the vast majority of parameters in this fit, the true value lies within the 95% posterior interval, as we would expect. Since we drew parameters from the priors for our model, we can see this result as rather general.

### Data fit
Next, we fit the observed data with our model.
```{r, eval = FALSE}
fit0 <- sampling(model0,
                 data = betas %$%
                   list(N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = cope_mean_scaled,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 control = list(max_treedepth = 15),
                 seed = 909)

save(fit0, file = "../../ignore/fit_model0.rda")
```

```{r echo = F}
load("../../ignore/fit_model0.rda")
```

```{r}
df_fit0 <- fit0 %>%
  as.data.frame() %>%
  as_tibble() %>%
  mutate(iteration = 1:n())

hyperparams <- df_fit0 %>%
  select(iteration, alpha, tau_roi, tau_subj)

eta_rois <- df_fit0 %>%
  select(iteration, tau_roi, starts_with("eta_roi")) %>%
  gather(key = "roi_num", value = "eta", starts_with("eta_roi")) %>%
  mutate(roi_num = as.integer(str_sub(roi_num, start = 9L, end = -2L)),
         eta_unscaled = tau_roi * eta * sd(betas$cope_mean)) %>%
  group_by(roi_num) %>%
  nest(.key = "iterations") %>%
  left_join(betas %>%
              select(roi_num, cope_mean, cope_mean_scaled) %>%
              group_by(roi_num) %>%
              summarize_all(mean),
            by = "roi_num") %>%
  mutate(summaries = map(iterations, ~.x %>%
                           summarize_at(vars(starts_with("eta")),
                                        funs(median = median,
                                             int_95_lower = quantile(., .025),
                                             int_95_upper = quantile(., .975),
                                             int_50_lower = quantile(., .25),
                                             int_50_upper = quantile(., .75))))) %>%
  unnest(summaries, .preserve = "iterations")

theta_rois <- df_fit0 %>%
  select(iteration, starts_with("theta_roi")) %>%
  gather(key = "roi_num", value = "theta", starts_with("theta_roi")) %>%
  mutate(roi_num = as.integer(str_sub(roi_num, start = 11L, end = -2L)),
         theta_unscaled = theta * sd(betas$cope_mean)) %>%
  group_by(roi_num) %>%
  nest(.key = "iterations") %>%
  left_join(betas %>%
              select(roi_num, cope_mean, cope_mean_scaled) %>%
              group_by(roi_num) %>%
              summarize_all(mean),
            by = "roi_num") %>%
  mutate(summaries = map(iterations, ~.x %>%
                           summarize_at(vars(starts_with("theta")),
                                        funs(median = median,
                                             int_95_lower = quantile(., .025),
                                             int_95_upper = quantile(., .975),
                                             int_50_lower = quantile(., .25),
                                             int_50_upper = quantile(., .75))))) %>%
  unnest(summaries, .preserve = "iterations")


```

### Plots?

SCALED (divided by sd(cope)):

```{r}
theta_rois %>%
  ggplot(aes(x = roi_num)) +
  geom_hline(yintercept = 0, linetype = 3) +
  geom_errorbar(aes(ymin = theta_int_95_lower, ymax = theta_int_95_upper), width = 0) +
  geom_point(aes(y = theta_median)) +
  geom_point(aes(y = cope_mean_scaled), color = "hotpink") +
  labs(x = "ROI number (arbitrary)",
       y = "COPE/beta value (SCALED arbitrary units)",
       title = "Bayesian estimates against original marginal means",
       subtitle = "Black: median estimates +- 95% predictive interval, pink: original mean estimate") +
  theme_bw()
```

UNSCALED (back on cope units):

```{r}
theta_rois %>%
  ggplot(aes(x = roi_num)) +
  geom_hline(yintercept = 0, linetype = 3) +
  geom_errorbar(aes(ymin = theta_unscaled_int_95_lower, ymax = theta_unscaled_int_95_upper), width = 0) +
  geom_point(aes(y = theta_unscaled_median)) +
  geom_point(aes(y = cope_mean), color = "hotpink") +
  labs(x = "ROI number (arbitrary)",
       y = "COPE/beta value (arbitrary units)",
       title = "Bayesian estimates against original marginal means",
       subtitle = "Black: median estimates +- 95% predictive interval, pink: original mean estimate") +
  theme_bw()
```

```{r}
# Plot data replicates
# Implemented with data.table. Sorry. Open to the possibility of recoding with tidyverse, just not right now
df_fit0 <- as.data.table(fit0)
df_fit0 <- df_fit[, grepl('rep_cope', colnames(df_fit)), with = F]
df_fit[, sim := 1:nrow(df_fit)]
df_fit0 <- melt(df_fit, id.vars = 'sim')
df_fit[, value := value * sd(betas$cope_mean)]
df_fit0 <- df_fit[, .(median = median(value),
                     lb = quantile(value, 0.025),
                     ub = quantile(value, 0.975)), by = variable][order(variable)]
df_fit[, subject_num := betas$subject_num]
df_fit[, roi_num := betas$roi_num]
df_fit[, true_value := betas$cope_mean]
df_fit0 <- df_fit[order(true_value)]

# Plot disregarding heirarchy
ggplot(df_fit, aes(x = 1:nrow(df_fit), y = median)) +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = 'yellow') +
  geom_line(color = 'darkred') + 
  geom_point(aes(y = true_value)) +
  labs(x = 'Observation number',
       y = 'COPE',
       title = 'Posterior predictive checks: replicate plots ignoring heirarchy',
       subtitle = 'Red: posterior median. Yellow: posterior 95% interval. Black: observed COPE')

# Plot by subject
df_subs <- df_fit[subject_num %in% sample(1:length(unique(subject_num)), 20)]
df_subs[, xplot := 1:.N, by = subject_num]
ggplot(df_subs, aes(x = xplot, y = median)) +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = 'yellow') +
  geom_point(aes(y = true_value), size = 0.3) +
  geom_line(color = 'darkred') + 
  facet_wrap('subject_num') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) +
  labs(x = 'Subject number (arbitrary)',
       y = 'COPE',
       title = 'Posterior predictive checks: replicate plots by subject, for a random subsample of subjects',
       subtitle = 'Red: posterior median. Yellow: posterior 95% interval. Black: observed COPE')

# Plot by roi
df_subs <- df_fit[roi_num %in% sample(1:length(unique(roi_num)), 20)]
df_subs[, xplot := 1:.N, by = roi_num]
ggplot(df_subs, aes(x = xplot, y = median)) +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = 'yellow') +
  geom_point(aes(y = true_value), size = 0.3) +
  geom_line(color = 'darkred') + 
  facet_wrap('roi_num') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) +
  labs(x = 'ROI number (arbitrary)',
       y = 'COPE',
       title = 'Posterior predictive checks: replicate plots by ROI, for a random subsample of ROIs',
       subtitle = 'Red: posterior median. Yellow: posterior 95% interval. Black: observed COPE')

```

```{r}
# Compare thetas to priors
df_fit0 <- as.data.table(fit0)
vars <- colnames(df_fit)
eta_rois <- df_fit[sample(1:nrow(df_fit), 20), grepl('eta_roi', vars) & !grepl('th', vars), with = F]
eta_subj <- df_fit[sample(1:nrow(df_fit), 20), grepl('eta_subj', vars) & !grepl('th', vars), with = F]

eta_rois[, sim := 1:.N]
eta_subj[, sim := 1:.N]

eta_rois <- melt(eta_rois, id.vars = 'sim')
eta_subj <- melt(eta_subj, id.vars = 'sim')

bw <- .2
n_subj <- length(unique(eta_subj$variable))
ggplot(eta_subj, aes(x = value)) + 
  geom_histogram(binwidth = bw) +
  facet_wrap('sim') +
  stat_function(fun = function(x, bw, n) dnorm(x) * bw * n, 
                args = c(bw = bw, n = n_subj),
                color = 'blue') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) + 
  labs(x = expression(eta),
       title = 'Estimated subject deviations agains the normal prior distribution',
       subtitle = 'Black: subject histogram, Blue: normal prior, Each facet represents a posterior draw')

n_roi <- length(unique(eta_rois$variable))
ggplot(eta_rois, aes(x = value)) + 
  geom_histogram(binwidth = bw) +
  facet_wrap('sim') +
  stat_function(fun = function(x, bw, n) dnorm(x) * bw * n, 
                args = c(bw = bw, n = n_roi),
                color = 'blue') +
  theme(strip.background = element_blank(),
    strip.text.x = element_blank()) + 
  labs(x = expression(eta),
       title = 'Estimated ROI deviations agains the normal prior distribution',
       subtitle = 'Black: ROI histogram, Blue: normal prior, Each facet represents a posterior draw')

```


## Model 1: Finite mixture hyper-distribution

### Stan code

```{stan, output.var = "model1", results = "hide", message = FALSE, warning = FALSE}
data {
  real beta_0; // middle alpha
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  real cope[N];               // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> fd[N]; // framewise displacement of each observation, varies by subject x wave
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
transformed data {
  int<lower=0> N_cell = N_roi * N_subj;
}
parameters {
  // real alpha; // general intercept
  simplex[3] phi; // mixing phroportions
  real<upper=0> beta_neg; // center of negative mixture component
  real<lower=0> beta_pos; // center of positive mixture component
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  matrix[N_roi, 3] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
transformed parameters {
  // hard coding 3 mixture components, shrug
  vector[3] beta; // all the mixture centers
  beta[1] = beta_neg;
  beta[2] = beta_0;
  beta[3] = beta_pos;
}
model {
  vector[3] log_phi = log(phi);  // cache log calculation

  // priors make the world go round
  // alpha ~ normal(0, 1);
  
  // weakly informative prior for all three betas
  beta_neg ~ normal(0, 5);
  beta_0 ~ normal(0, 5);
  beta_pos ~ normal(0, 5);
  
  // wip for taus
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  
  // wip for etas
  for (k in 1:3) {
    eta_roi[, k] ~ normal(0, 1);
  }
  
  eta_subj ~ normal(0, 1);
  
  // likelihood stuff
  for (n in 1:N) {
    vector[3] lps = log_phi;
    for (k in 1:3)
      // lps[k] += normal_lpdf(y[n] | mu[k], sigma[k]); // from 2.10
      lps[k] += normal_lpdf(cope[n] | beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]);
    target += log_sum_exp(lps);
  }
  
  // This was the old one, leaving here just in case
  // cope ~ normal(alpha + tau_roi * eta_roi[roi] + tau_subj * eta_subj[subj], varcope);
}
generated quantities {
  // generated thetas, one for each component
  matrix[N_roi, 3] theta_roi;
  for (k in 1:3) {
    theta_roi[, k] = beta[k] + tau_roi * eta_roi[, k];
  }
  
//  vector [N] rep_cope; // Create data replicates

//  for (i in 1:N)
//    rep_cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}

```

```{stan, output.var = "model1.2", results = "hide", message = FALSE, warning = FALSE}
data {
  int<lower=1> K; // number of mixture components
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  real cope[N];               // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> fd[N]; // framewise displacement of each observation, varies by subject x wave
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
transformed data {
  int<lower=0> N_cell = N_roi * N_subj;
}
parameters {
  // real alpha; // general intercept
  simplex[K] phi; // mixing phroportions
  ordered[K] beta; // centers of mixture components
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  matrix[N_roi, K] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
model {
  vector[2] log_phi = log(phi);  // cache log calculation

  // priors make the world go round
  // alpha ~ normal(0, 1);
  
  // weakly informative prior for all betas
  beta ~ normal(0, 2);
  
  // wip for taus
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  
  // wip for etas
  for (k in 1:K) {
    eta_roi[, k] ~ normal(0, 1);
  }
  
  eta_subj ~ normal(0, 1);
  
  // likelihood stuff
  for (n in 1:N) {
    vector[K] lps = log_phi;
    for (k in 1:K)
      // lps[k] += normal_lpdf(y[n] | mu[k], sigma[k]); // from 2.10
      lps[k] += normal_lpdf(cope[n] | beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]);
    target += log_sum_exp(lps);
  }
}
generated quantities {
  // generated thetas, one for each component
  matrix[N_roi, K] theta_roi;
  matrix[N, K] p;
  
  for (k in 1:K) {
    theta_roi[, k] = beta[k] + tau_roi * eta_roi[, k];
  }
  
  for (n in 1:N){
    vector[K] p_raw;
    for (k in 1:K){
      p_raw[k] = phi[k] * exp(normal_log(cope[n], beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]));
    }
    for (k in 1:K){
      p[n,k] = p_raw[k]/sum(p_raw);
    }
  }
//  vector [N] rep_cope; // Create data replicates

//  for (i in 1:N)
//    rep_cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}

```

```{stan, output.var = "model1.3", results = "hide", message = FALSE, warning = FALSE}
data {
  int<lower=1> K; // number of mixture components
  ordered[K] beta; // centers of mixture components
  int<lower=0> N;          // number of rois x observations (subjs x waves)
  int<lower=0> N_roi;
  int<lower=0> N_subj;
  real cope[N];               // estimated effects for each observation of roi
  int<lower=1, upper=N_roi> roi[N]; // ROI ID of each observation
  int<lower=1, upper=N_subj> subj[N]; // subject ID of each observation
  real<lower=0> fd[N]; // framewise displacement of each observation, varies by subject x wave
  real<lower=0> varcope[N];  // s.e. of effect estimates
}
transformed data {
  int<lower=0> N_cell = N_roi * N_subj;
}
parameters {
  // real alpha; // general intercept
  simplex[K] phi; // mixing phroportions
  real<lower=0> tau_roi;
  real<lower=0> tau_subj;
  matrix[N_roi, K] eta_roi; // centered parameterization of roi-specific effect estimate
  vector[N_subj] eta_subj; // centered parameterization of roi-specific effect estimate
}
model {
  vector[2] log_phi = log(phi);  // cache log calculation

  // priors make the world go round
  // alpha ~ normal(0, 1);
  
  // rather informative prior for all betas
  beta ~ normal(0, 1);
  
  // wip for taus
  tau_roi ~ normal(0, 1);
  tau_subj ~ normal(0, 1);
  
  // wip for etas
  for (k in 1:K) {
    eta_roi[, k] ~ normal(0, 1);
  }
  
  eta_subj ~ normal(0, 1);
  
  // likelihood stuff
  for (n in 1:N) {
    vector[K] lps = log_phi;
    for (k in 1:K)
      // lps[k] += normal_lpdf(y[n] | mu[k], sigma[k]); // from 2.10
      lps[k] += normal_lpdf(cope[n] | beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]);
    target += log_sum_exp(lps);
  }
}
generated quantities {
  // generated thetas, one for each component
  matrix[N_roi, K] theta_roi;
  matrix[N, K] p;
  
  for (k in 1:K) {
    theta_roi[, k] = beta[k] + tau_roi * eta_roi[, k];
  }
  
  for (n in 1:N){
    vector[K] p_raw;
    for (k in 1:K){
      p_raw[k] = phi[k] * exp(normal_log(cope[n], beta[k] + tau_roi * eta_roi[roi[n], k] + tau_subj * eta_subj[subj[n]], varcope[n]));
    }
    for (k in 1:K){
      p[n,k] = p_raw[k]/sum(p_raw);
    }
  }
//  vector [N] rep_cope; // Create data replicates

//  for (i in 1:N)
//    rep_cope[i] = normal_rng(alpha + tau_roi * eta_roi[roi][i] + tau_subj * eta_subj[subj][i], varcope[i]);
}

```

```{r, eval = FALSE}
fit1.2 <- sampling(model1.2,
                 data = betas %$%
                   list(K = 2L,
                        N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = cope_mean_scaled,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 iter = 200,
                 control = list(max_treedepth = 15))
```

```{r, eval = FALSE}
fit1.3 <- sampling(model1.3,
                 data = betas %$%
                   list(K = 2L,
                        beta = c(0.3, 1),
                        N = nrow(.),
                        N_roi = max(roi_num),
                        N_subj = max(subject_num),
                        cope = cope_mean_scaled,
                        roi = roi_num,
                        subj = subject_num,
                        fd = meanFD_included_trs,
                        varcope = cope_sd_scaled),
                 iter = 200,
                 control = list(max_treedepth = 15))
```

### Plots?

Temporarily need to reload model object when done separately
```{r}
load('fit_model0.rda')

## Redundant bit
# 
# df_fit0 <- fit %>%
#   as.data.frame() %>%
#   as_tibble() %>%
#   mutate(iteration = 1:n())
# 
# theta_rois <- df_fit0 %>%
#   select(iteration, starts_with("theta_roi")) %>%
#   gather(key = "roi_num", value = "theta", starts_with("theta_roi")) %>%
#   mutate(roi_num = as.integer(stringr::str_sub(roi_num, start = 11L, end = -2L)),
#          theta_unscaled = theta * sd(betas$cope_mean)) %>%
#   group_by(roi_num) %>%
#   nest(.key = "iterations") %>%
#   left_join(betas %>%
#               select(roi_num, cope_mean, cope_mean_scaled) %>%
#               group_by(roi_num) %>%
#               summarize_all(mean),
#             by = "roi_num") %>%
#   mutate(summaries = map(iterations, ~.x %>%
#                            summarize_at(vars(starts_with("theta")),
#                                         funs(median = median,
#                                              int_95_lower = quantile(., .025),
#                                              int_95_upper = quantile(., .975),
#                                              int_50_lower = quantile(., .25),
#                                              int_50_upper = quantile(., .75))))) %>%
#   unnest(summaries, .preserve = "iterations") 

# Save out the thetas for each roi
theta_rois = dplyr::select(betas, roi, roi_num) %>%
  unique() %>%
  left_join(theta_rois, .) %>%
  select(-iterations)

write.csv(theta_rois, file = '../../estimates/spreadsheets/mod0.csv', row.names = F, quote = F)
```

